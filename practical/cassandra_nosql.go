package practical

import (
	"context"
	"fmt"
	"sync"
	"sync/atomic"
	"time"

	"github.com/gocql/gocql"
)

// CassandraNoSQL - Cassandraã‚’ä½¿ã£ãŸåˆ†æ•£NoSQLå‡¦ç†
type CassandraNoSQL struct {
	cluster *gocql.ClusterConfig
	session *gocql.Session
	mu      sync.RWMutex
}

// NewCassandraNoSQL - Cassandraæ¥ç¶šã®åˆæœŸåŒ–
func NewCassandraNoSQL(hosts []string) (*CassandraNoSQL, error) {
	cluster := gocql.NewCluster(hosts...)
	cluster.Keyspace = "async_practice"
	cluster.Consistency = gocql.Quorum
	cluster.ProtoVersion = 4
	cluster.Timeout = 5 * time.Second
	cluster.ConnectTimeout = 5 * time.Second

	// æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®è¨­å®š
	cluster.NumConns = 3
	cluster.PoolConfig.HostSelectionPolicy = gocql.TokenAwareHostPolicy(gocql.RoundRobinHostPolicy())

	session, err := cluster.CreateSession()
	if err != nil {
		// ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼ˆå®Ÿéš›ã®CassandraãŒåˆ©ç”¨ã§ããªã„å ´åˆï¼‰
		fmt.Println("âš  Cassandraã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
		return &CassandraNoSQL{
			cluster: cluster,
			session: nil, // ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§ã¯nilã‚»ãƒƒã‚·ãƒ§ãƒ³
		}, nil
	}

	c := &CassandraNoSQL{
		cluster: cluster,
		session: session,
	}

	// ã‚­ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
	if err := c.initializeSchema(); err != nil {
		fmt.Printf("ã‚¹ã‚­ãƒ¼ãƒåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: %v\n", err)
	}

	return c, nil
}

// initializeSchema - ã‚¹ã‚­ãƒ¼ãƒã®åˆæœŸåŒ–
func (c *CassandraNoSQL) initializeSchema() error {
	if c.session == nil {
		return nil // ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰
	}

	queries := []string{
		// ã‚­ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆ
		`CREATE KEYSPACE IF NOT EXISTS async_practice
		 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3}`,

		// ã‚¿ã‚¤ãƒ ã‚·ãƒªãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
		`CREATE TABLE IF NOT EXISTS async_practice.timeseries (
			partition_key text,
			timestamp timestamp,
			sensor_id text,
			value double,
			metadata map<text, text>,
			PRIMARY KEY (partition_key, timestamp, sensor_id)
		) WITH CLUSTERING ORDER BY (timestamp DESC)`,

		// ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ãƒ†ãƒ¼ãƒ–ãƒ«
		`CREATE TABLE IF NOT EXISTS async_practice.wide_rows (
			row_key text,
			column_name text,
			column_value blob,
			timestamp timestamp,
			PRIMARY KEY (row_key, column_name)
		)`,

		// ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«
		`CREATE TABLE IF NOT EXISTS async_practice.counters (
			counter_id text PRIMARY KEY,
			count counter
		)`,

		// ãƒãƒ†ãƒªã‚¢ãƒ©ã‚¤ã‚ºãƒ‰ãƒ“ãƒ¥ãƒ¼
		`CREATE MATERIALIZED VIEW IF NOT EXISTS async_practice.timeseries_by_sensor AS
			SELECT * FROM async_practice.timeseries
			WHERE sensor_id IS NOT NULL AND partition_key IS NOT NULL AND timestamp IS NOT NULL
			PRIMARY KEY (sensor_id, timestamp, partition_key)
			WITH CLUSTERING ORDER BY (timestamp DESC)`,
	}

	for _, query := range queries {
		if err := c.session.Query(query).Exec(); err != nil {
			// ã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ï¼ˆæ—¢å­˜ã®å ´åˆãªã©ï¼‰
			fmt.Printf("ã‚¹ã‚­ãƒ¼ãƒã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: %v\n", err)
		}
	}

	return nil
}

// TimeSeriesIngestion - ã‚¿ã‚¤ãƒ ã‚·ãƒªãƒ¼ã‚ºãƒ‡ãƒ¼ã‚¿ã®ä¸¦åˆ—å–ã‚Šè¾¼ã¿
func (c *CassandraNoSQL) TimeSeriesIngestion(ctx context.Context) {
	fmt.Println("\nğŸ—„ Cassandra ã‚¿ã‚¤ãƒ ã‚·ãƒªãƒ¼ã‚ºå–ã‚Šè¾¼ã¿ãƒ‡ãƒ¢")
	fmt.Println("=" + repeatString("=", 50))

	if c.session == nil {
		c.runDemoMode(ctx)
		return
	}

	// ãƒ¡ãƒˆãƒªã‚¯ã‚¹
	var (
		totalInserted  int64
		totalFailed    int64
		totalBatches   int64
	)

	// ãƒ‡ãƒ¼ã‚¿ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼
	dataStream := make(chan SensorData, 1000)

	// ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆä¸¦åˆ—ï¼‰
	var producerWg sync.WaitGroup
	numSensors := 10
	for i := 0; i < numSensors; i++ {
		producerWg.Add(1)
		go func(sensorID int) {
			defer producerWg.Done()
			c.generateSensorData(ctx, sensorID, dataStream)
		}(i)
	}

	// ãƒãƒƒãƒæ›¸ãè¾¼ã¿ãƒ¯ãƒ¼ã‚«ãƒ¼
	var writerWg sync.WaitGroup
	numWriters := 5
	batchSize := 50

	for i := 0; i < numWriters; i++ {
		writerWg.Add(1)
		go func(writerID int) {
			defer writerWg.Done()
			c.batchWriter(ctx, writerID, dataStream, batchSize,
				&totalInserted, &totalFailed, &totalBatches)
		}(i)
	}

	// çµ±è¨ˆè¡¨ç¤º
	go c.displayStats(ctx, &totalInserted, &totalFailed, &totalBatches)

	// ä¸¦åˆ—èª­ã¿å–ã‚Šãƒ‡ãƒ¢
	go c.parallelReads(ctx)

	// å®Ÿè¡Œ
	select {
	case <-ctx.Done():
	case <-time.After(15 * time.Second):
	}

	// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
	close(dataStream)
	producerWg.Wait()
	writerWg.Wait()

	fmt.Printf("\nğŸ“Š æœ€çµ‚çµ±è¨ˆ: æŒ¿å…¥=%d, å¤±æ•—=%d, ãƒãƒƒãƒ=%d\n",
		atomic.LoadInt64(&totalInserted),
		atomic.LoadInt64(&totalFailed),
		atomic.LoadInt64(&totalBatches))
}

// SensorData - ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿
type SensorData struct {
	SensorID    string
	Timestamp   time.Time
	Value       float64
	Metadata    map[string]string
}

// generateSensorData - ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
func (c *CassandraNoSQL) generateSensorData(ctx context.Context, sensorID int, out chan<- SensorData) {
	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()

	sensorName := fmt.Sprintf("sensor_%d", sensorID)
	location := []string{"tokyo", "osaka", "nagoya"}[sensorID%3]

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			data := SensorData{
				SensorID:  sensorName,
				Timestamp: time.Now(),
				Value:     float64(sensorID*100) + float64(time.Now().Unix()%100),
				Metadata: map[string]string{
					"location": location,
					"type":     "temperature",
					"unit":     "celsius",
				},
			}

			select {
			case out <- data:
			default:
				// ãƒãƒƒãƒ•ã‚¡ãƒ•ãƒ«ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
			}
		}
	}
}

// batchWriter - ãƒãƒƒãƒæ›¸ãè¾¼ã¿ãƒ¯ãƒ¼ã‚«ãƒ¼
func (c *CassandraNoSQL) batchWriter(ctx context.Context, writerID int,
	dataStream <-chan SensorData, batchSize int,
	totalInserted, totalFailed, totalBatches *int64) {

	batch := make([]SensorData, 0, batchSize)
	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()

	flush := func() {
		if len(batch) == 0 {
			return
		}

		// ãƒãƒƒãƒã‚¯ã‚¨ãƒªã®æº–å‚™
		batchQuery := c.session.NewBatch(gocql.LoggedBatch)
		batchQuery.SetConsistency(gocql.LocalQuorum)

		for _, data := range batch {
			// ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã®ç”Ÿæˆï¼ˆæ—¥ä»˜ãƒ™ãƒ¼ã‚¹ï¼‰
			partitionKey := fmt.Sprintf("%s_%s",
				data.SensorID,
				data.Timestamp.Format("2006-01-02"))

			batchQuery.Query(`
				INSERT INTO async_practice.timeseries
				(partition_key, timestamp, sensor_id, value, metadata)
				VALUES (?, ?, ?, ?, ?)`,
				partitionKey,
				data.Timestamp,
				data.SensorID,
				data.Value,
				data.Metadata,
			)
		}

		// ãƒãƒƒãƒå®Ÿè¡Œï¼ˆãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
		var err error
		for retry := 0; retry < 3; retry++ {
			err = c.session.ExecuteBatch(batchQuery)
			if err == nil {
				break
			}
			time.Sleep(time.Duration(retry*100) * time.Millisecond)
		}

		if err != nil {
			atomic.AddInt64(totalFailed, int64(len(batch)))
			fmt.Printf("  Writer %d: ãƒãƒƒãƒæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: %v\n", writerID, err)
		} else {
			atomic.AddInt64(totalInserted, int64(len(batch)))
			atomic.AddInt64(totalBatches, 1)
		}

		batch = batch[:0]
	}

	for {
		select {
		case <-ctx.Done():
			flush()
			return
		case data, ok := <-dataStream:
			if !ok {
				flush()
				return
			}
			batch = append(batch, data)
			if len(batch) >= batchSize {
				flush()
			}
		case <-ticker.C:
			flush()
		}
	}
}

// parallelReads - ä¸¦åˆ—èª­ã¿å–ã‚Šãƒ‡ãƒ¢
func (c *CassandraNoSQL) parallelReads(ctx context.Context) {
	if c.session == nil {
		return // ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰
	}

	ticker := time.NewTicker(3 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			// ä¸¦åˆ—ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
			var wg sync.WaitGroup
			queries := []struct {
				name  string
				query string
			}{
				{
					name: "æœ€æ–°ãƒ‡ãƒ¼ã‚¿",
					query: `SELECT sensor_id, timestamp, value
							FROM async_practice.timeseries
							LIMIT 10`,
				},
				{
					name: "ã‚»ãƒ³ã‚µãƒ¼åˆ¥é›†è¨ˆ",
					query: `SELECT sensor_id, COUNT(*) as count
							FROM async_practice.timeseries
							GROUP BY sensor_id
							ALLOW FILTERING`,
				},
			}

			fmt.Println("\nğŸ“– ä¸¦åˆ—èª­ã¿å–ã‚Šçµæœ:")
			for _, q := range queries {
				wg.Add(1)
				go func(name, query string) {
					defer wg.Done()

					iter := c.session.Query(query).Iter()

					var results []map[string]interface{}
					m := make(map[string]interface{})
					for iter.MapScan(m) {
						results = append(results, m)
						m = make(map[string]interface{})
					}

					if err := iter.Close(); err != nil {
						fmt.Printf("  %s: ã‚¨ãƒ©ãƒ¼ %v\n", name, err)
					} else {
						fmt.Printf("  %s: %dä»¶å–å¾—\n", name, len(results))
					}
				}(q.name, q.query)
			}
			wg.Wait()
		}
	}
}

// displayStats - çµ±è¨ˆè¡¨ç¤º
func (c *CassandraNoSQL) displayStats(ctx context.Context,
	totalInserted, totalFailed, totalBatches *int64) {

	ticker := time.NewTicker(2 * time.Second)
	defer ticker.Stop()

	var lastInserted int64
	startTime := time.Now()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			inserted := atomic.LoadInt64(totalInserted)
			failed := atomic.LoadInt64(totalFailed)
			batches := atomic.LoadInt64(totalBatches)

			// ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—
			throughput := float64(inserted-lastInserted) / 2.0 // per second
			elapsed := time.Since(startTime).Seconds()
			avgThroughput := float64(inserted) / elapsed

			fmt.Printf("\nğŸ“Š çµ±è¨ˆ: æŒ¿å…¥=%d, å¤±æ•—=%d, ãƒãƒƒãƒ=%d, "+
				"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ=%.1f/ç§’, å¹³å‡=%.1f/ç§’\n",
				inserted, failed, batches, throughput, avgThroughput)

			lastInserted = inserted
		}
	}
}

// WideColumnOperations - ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ æ“ä½œãƒ‡ãƒ¢
func (c *CassandraNoSQL) WideColumnOperations(ctx context.Context) {
	fmt.Println("\nğŸ“‹ Cassandra ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ãƒ‡ãƒ¢")
	fmt.Println("=" + repeatString("=", 50))

	if c.session == nil {
		fmt.Println("ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰: ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ æ“ä½œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
		c.simulateWideColumns()
		return
	}

	// ãƒ¯ã‚¤ãƒ‰ãƒ­ãƒ¼ã®ä½œæˆ
	rowKey := fmt.Sprintf("user_%d", time.Now().Unix())

	// ä¸¦åˆ—ã§ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
	var wg sync.WaitGroup
	numColumns := 1000

	for i := 0; i < numColumns; i++ {
		wg.Add(1)
		go func(colIndex int) {
			defer wg.Done()

			columnName := fmt.Sprintf("col_%d", colIndex)
			columnValue := []byte(fmt.Sprintf("value_%d_%d", colIndex, time.Now().Unix()))

			err := c.session.Query(`
				INSERT INTO async_practice.wide_rows
				(row_key, column_name, column_value, timestamp)
				VALUES (?, ?, ?, ?)`,
				rowKey, columnName, columnValue, time.Now(),
			).Exec()

			if err != nil && colIndex%100 == 0 {
				fmt.Printf("  ã‚«ãƒ©ãƒ æŒ¿å…¥ã‚¨ãƒ©ãƒ¼ %d: %v\n", colIndex, err)
			}
		}(i)
	}

	wg.Wait()
	fmt.Printf("  âœ“ %då€‹ã®ã‚«ãƒ©ãƒ ã‚’æŒ¿å…¥ã—ã¾ã—ãŸ (row_key: %s)\n", numColumns, rowKey)

	// ã‚¹ãƒ©ã‚¤ã‚¹ã‚¯ã‚¨ãƒª
	fmt.Println("\n  ã‚«ãƒ©ãƒ ã‚¹ãƒ©ã‚¤ã‚¹èª­ã¿å–ã‚Š:")
	iter := c.session.Query(`
		SELECT column_name, column_value
		FROM async_practice.wide_rows
		WHERE row_key = ?
		LIMIT 10`,
		rowKey,
	).Iter()

	var columnName string
	var columnValue []byte
	count := 0
	for iter.Scan(&columnName, &columnValue) {
		fmt.Printf("    %s: %s\n", columnName, string(columnValue))
		count++
	}

	if err := iter.Close(); err != nil {
		fmt.Printf("  èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: %v\n", err)
	} else {
		fmt.Printf("  âœ“ %då€‹ã®ã‚«ãƒ©ãƒ ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸ\n", count)
	}
}

// CounterOperations - ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ“ä½œãƒ‡ãƒ¢
func (c *CassandraNoSQL) CounterOperations(ctx context.Context) {
	fmt.Println("\nğŸ”¢ Cassandra ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ãƒ‡ãƒ¢")
	fmt.Println("=" + repeatString("=", 50))

	if c.session == nil {
		fmt.Println("ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰: ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ“ä½œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
		c.simulateCounters()
		return
	}

	counterID := fmt.Sprintf("counter_%d", time.Now().Unix())

	// ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®ä¸¦åˆ—æ›´æ–°
	var wg sync.WaitGroup
	numWorkers := 10
	incrementsPerWorker := 100

	fmt.Printf("  %då€‹ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ä¸¦åˆ—ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ›´æ–°...\n", numWorkers)

	for w := 0; w < numWorkers; w++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for i := 0; i < incrementsPerWorker; i++ {
				err := c.session.Query(`
					UPDATE async_practice.counters
					SET count = count + ?
					WHERE counter_id = ?`,
					1, counterID,
				).Exec()

				if err != nil && i == 0 {
					fmt.Printf("    Worker %d: ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼æ›´æ–°ã‚¨ãƒ©ãƒ¼: %v\n", workerID, err)
				}
			}
		}(w)
	}

	wg.Wait()

	// ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å€¤ã®èª­ã¿å–ã‚Š
	var count int64
	err := c.session.Query(`
		SELECT count FROM async_practice.counters
		WHERE counter_id = ?`,
		counterID,
	).Scan(&count)

	if err != nil {
		fmt.Printf("  ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: %v\n", err)
	} else {
		expected := numWorkers * incrementsPerWorker
		fmt.Printf("  âœ“ ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å€¤: %d (æœŸå¾…å€¤: %d)\n", count, expected)
	}
}

// runDemoMode - ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œ
func (c *CassandraNoSQL) runDemoMode(ctx context.Context) {
	fmt.Println("\nğŸ­ ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰: Cassandraã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")

	// ä»®æƒ³çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆã‚¢
	type VirtualCassandra struct {
		mu    sync.RWMutex
		data  map[string]map[string]interface{}
		count int64
	}

	vc := &VirtualCassandra{
		data: make(map[string]map[string]interface{}),
	}

	// ä¸¦åˆ—æ›¸ãè¾¼ã¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
	var wg sync.WaitGroup
	for i := 0; i < 5; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()
			for j := 0; j < 100; j++ {
				vc.mu.Lock()
				key := fmt.Sprintf("key_%d_%d", id, j)
				vc.data[key] = map[string]interface{}{
					"value":     j,
					"timestamp": time.Now(),
				}
				atomic.AddInt64(&vc.count, 1)
				vc.mu.Unlock()

				if j%20 == 0 {
					fmt.Printf("  Worker %d: %dä»¶å‡¦ç†\n", id, j)
				}
			}
		}(i)
	}

	wg.Wait()
	fmt.Printf("\n  âœ“ ãƒ‡ãƒ¢å®Œäº†: %dä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†\n", atomic.LoadInt64(&vc.count))
}

// simulateWideColumns - ãƒ¯ã‚¤ãƒ‰ã‚«ãƒ©ãƒ ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
func (c *CassandraNoSQL) simulateWideColumns() {
	row := make(map[string]interface{})
	var mu sync.Mutex

	// ä¸¦åˆ—ã‚«ãƒ©ãƒ è¿½åŠ 
	var wg sync.WaitGroup
	for i := 0; i < 100; i++ {
		wg.Add(1)
		go func(col int) {
			defer wg.Done()
			mu.Lock()
			row[fmt.Sprintf("col_%d", col)] = fmt.Sprintf("value_%d", col)
			mu.Unlock()
		}(i)
	}
	wg.Wait()

	fmt.Printf("  âœ“ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: %då€‹ã®ã‚«ãƒ©ãƒ ã‚’æŒã¤ãƒ¯ã‚¤ãƒ‰ãƒ­ãƒ¼\n", len(row))
}

// simulateCounters - ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
func (c *CassandraNoSQL) simulateCounters() {
	var counter int64

	// ä¸¦åˆ—ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
	var wg sync.WaitGroup
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for j := 0; j < 100; j++ {
				atomic.AddInt64(&counter, 1)
			}
		}()
	}
	wg.Wait()

	fmt.Printf("  âœ“ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼å€¤ = %d\n", counter)
}

// Close - ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
func (c *CassandraNoSQL) Close() {
	if c.session != nil {
		c.session.Close()
	}
}